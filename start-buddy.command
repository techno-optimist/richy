#!/bin/bash -l
cd "$(dirname "$0")"

# Load nvm/fnm if present
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && . "$NVM_DIR/nvm.sh"
[ -s "$HOME/.fnm/fnm" ] && eval "$(fnm env)"

echo ""
echo "  โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
echo "  โ       ๐ค  Starting Richy         โ"
echo "  โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
echo ""

# โโ Verify Node.js โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
if ! command -v node &>/dev/null; then
  echo "  โ Node.js not found. Install it first:"
  echo "     https://nodejs.org"
  read -p "  Press Enter to close..."
  exit 1
fi
echo "  Node $(node -v) | npm $(npm -v)"

# โโ Install dependencies if needed โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
if [ ! -d "node_modules" ]; then
  echo ""
  echo "  ๐ฆ Installing dependencies (first run)..."
  npm install
fi

# โโ Kill any stale Richy server processes โโโโโโโโโโโโโโโโโโโโโโโโโโโ
STALE_PIDS=$(lsof -i :3000 -sST:LISTEN -t 2>/dev/null)
if [ -n "$STALE_PIDS" ]; then
  echo ""
  echo "  ๐งน Killing old server on port 3000 (PIDs: $STALE_PIDS)..."
  echo "$STALE_PIDS" | xargs kill -9 2>/dev/null
  sleep 1
fi

# Clean stale lock files
rm -f .next/dev/lock

# โโ Ensure Ollama is running (for background AI tasks) โโโโโโโโโโโโโโ
if command -v ollama &>/dev/null; then
  if ! curl -s -o /dev/null http://localhost:11434/api/tags 2>/dev/null; then
    echo ""
    echo "  ๐ฆ Starting Ollama..."
    ollama serve &>/dev/null &
    # Wait up to 10s for Ollama to be ready
    OLLAMA_TRIES=0
    until curl -s -o /dev/null http://localhost:11434/api/tags 2>/dev/null; do
      sleep 1
      OLLAMA_TRIES=$((OLLAMA_TRIES + 1))
      if [ $OLLAMA_TRIES -gt 10 ]; then
        echo "  โ๏ธ  Ollama didn't start โ background AI will fall back to API"
        break
      fi
    done
    if [ $OLLAMA_TRIES -le 10 ]; then
      echo "  โ Ollama ready"
    fi
  else
    echo "  โ Ollama already running"
  fi
else
  echo "  โน๏ธ  Ollama not installed โ background AI will use API provider"
fi

# โโ Start Richy โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
echo ""
echo "  โณ Starting server..."
echo ""
npm run dev &
SERVER_PID=$!

# Wait for server to be ready (timeout after 45s)
TRIES=0
until curl -s -o /dev/null http://localhost:3000 2>/dev/null; do
  sleep 1
  TRIES=$((TRIES + 1))
  if [ $TRIES -gt 45 ]; then
    echo ""
    echo "  โ Server failed to start. Check the output above for errors."
    read -p "  Press Enter to close..."
    exit 1
  fi
done

echo ""
echo "  โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
echo "  โ   โ  Richy is ready!            โ"
echo "  โ   http://localhost:3000          โ"
echo "  โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
echo ""
open http://localhost:3000

# Keep running until user closes terminal
wait $SERVER_PID
